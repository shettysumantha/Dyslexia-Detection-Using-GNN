{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Necessary imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import networkx as nx\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries for Data Gathering & Manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib.pyplot import figure\n",
    "from scipy.spatial.distance import euclidean as eu\n",
    "import math\n",
    "from scipy import signal\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import glob\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "# Importing Libraries for Binning\n",
    "import numpy as np \n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "from sklearn import preprocessing\n",
    "from scipy.fftpack import fft, ifft\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Importing the necessary libraries for building neural network and k-means clustering\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Path to the folders containing the data\n",
    "dyslexia_folder = \"Data/Dyslexic\"\n",
    "control_folder = \"Data/Control\"\n",
    "\n",
    "# Function to load data from folder\n",
    "def load_data_from_folder(folder, label):\n",
    "    data_list = []\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            data = pd.read_csv(os.path.join(folder, filename))\n",
    "            # Create a unique identifier for each patient based on CSV file name\n",
    "            data[\"patient_id\"] = filename.split(\".\")[0]  # Extract patient ID from filename\n",
    "            data[\"label\"] = label  # Add label column\n",
    "            \n",
    "            # Determine gender and reading ability based on filename\n",
    "            if filename.endswith(\"1.csv\") or filename.endswith(\"3.csv\"):\n",
    "                data[\"gender\"] = \"male\"\n",
    "                data[\"reading_ability\"] = \"disabled\"\n",
    "            else:\n",
    "                data[\"gender\"] = \"female\"\n",
    "                data[\"reading_ability\"] = \"enabled\"\n",
    "            \n",
    "            data_list.append(data)\n",
    "    return data_list\n",
    "\n",
    "# Load dyslexia samples\n",
    "D_data = load_data_from_folder(dyslexia_folder, \"dyslexia\")\n",
    "\n",
    "# Load control samples\n",
    "C_data = load_data_from_folder(control_folder, \"control\")\n",
    "\n",
    "# Combine data into a single DataFrame\n",
    "df = pd.concat(D_data + C_data, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>T</th>\n",
       "      <th>LX</th>\n",
       "      <th>LY</th>\n",
       "      <th>RX</th>\n",
       "      <th>RY</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>label</th>\n",
       "      <th>gender</th>\n",
       "      <th>reading_ability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>111JA2</td>\n",
       "      <td>dyslexia</td>\n",
       "      <td>female</td>\n",
       "      <td>enabled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.65535</td>\n",
       "      <td>-0.65536</td>\n",
       "      <td>111JA2</td>\n",
       "      <td>dyslexia</td>\n",
       "      <td>female</td>\n",
       "      <td>enabled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.65537</td>\n",
       "      <td>0.65536</td>\n",
       "      <td>-1.31073</td>\n",
       "      <td>111JA2</td>\n",
       "      <td>dyslexia</td>\n",
       "      <td>female</td>\n",
       "      <td>enabled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.65536</td>\n",
       "      <td>-1.96609</td>\n",
       "      <td>0.65536</td>\n",
       "      <td>-1.96609</td>\n",
       "      <td>111JA2</td>\n",
       "      <td>dyslexia</td>\n",
       "      <td>female</td>\n",
       "      <td>enabled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.65536</td>\n",
       "      <td>-1.96609</td>\n",
       "      <td>1.31072</td>\n",
       "      <td>-1.96609</td>\n",
       "      <td>111JA2</td>\n",
       "      <td>dyslexia</td>\n",
       "      <td>female</td>\n",
       "      <td>enabled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325059</th>\n",
       "      <td>1494</td>\n",
       "      <td>29880.0</td>\n",
       "      <td>-49.15286</td>\n",
       "      <td>57.01693</td>\n",
       "      <td>-48.49750</td>\n",
       "      <td>57.01693</td>\n",
       "      <td>831PA3</td>\n",
       "      <td>control</td>\n",
       "      <td>male</td>\n",
       "      <td>disabled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325060</th>\n",
       "      <td>1495</td>\n",
       "      <td>29900.0</td>\n",
       "      <td>-49.15286</td>\n",
       "      <td>57.01693</td>\n",
       "      <td>-48.49750</td>\n",
       "      <td>57.01693</td>\n",
       "      <td>831PA3</td>\n",
       "      <td>control</td>\n",
       "      <td>male</td>\n",
       "      <td>disabled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325061</th>\n",
       "      <td>1496</td>\n",
       "      <td>29920.0</td>\n",
       "      <td>-49.15286</td>\n",
       "      <td>57.01693</td>\n",
       "      <td>-48.49750</td>\n",
       "      <td>57.01693</td>\n",
       "      <td>831PA3</td>\n",
       "      <td>control</td>\n",
       "      <td>male</td>\n",
       "      <td>disabled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325062</th>\n",
       "      <td>1497</td>\n",
       "      <td>29940.0</td>\n",
       "      <td>-49.15286</td>\n",
       "      <td>57.01693</td>\n",
       "      <td>-48.49750</td>\n",
       "      <td>57.01693</td>\n",
       "      <td>831PA3</td>\n",
       "      <td>control</td>\n",
       "      <td>male</td>\n",
       "      <td>disabled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325063</th>\n",
       "      <td>1498</td>\n",
       "      <td>29960.0</td>\n",
       "      <td>-49.15286</td>\n",
       "      <td>57.01693</td>\n",
       "      <td>-48.49750</td>\n",
       "      <td>57.01693</td>\n",
       "      <td>831PA3</td>\n",
       "      <td>control</td>\n",
       "      <td>male</td>\n",
       "      <td>disabled</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>325064 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0        T        LX        LY        RX        RY  \\\n",
       "0                0      0.0   0.00000   0.00000   0.00000   0.00000   \n",
       "1                1     20.0  -0.00001   0.00000   0.65535  -0.65536   \n",
       "2                2     40.0  -0.00001  -0.65537   0.65536  -1.31073   \n",
       "3                3     60.0   0.65536  -1.96609   0.65536  -1.96609   \n",
       "4                4     80.0   0.65536  -1.96609   1.31072  -1.96609   \n",
       "...            ...      ...       ...       ...       ...       ...   \n",
       "325059        1494  29880.0 -49.15286  57.01693 -48.49750  57.01693   \n",
       "325060        1495  29900.0 -49.15286  57.01693 -48.49750  57.01693   \n",
       "325061        1496  29920.0 -49.15286  57.01693 -48.49750  57.01693   \n",
       "325062        1497  29940.0 -49.15286  57.01693 -48.49750  57.01693   \n",
       "325063        1498  29960.0 -49.15286  57.01693 -48.49750  57.01693   \n",
       "\n",
       "       patient_id     label  gender reading_ability  \n",
       "0          111JA2  dyslexia  female         enabled  \n",
       "1          111JA2  dyslexia  female         enabled  \n",
       "2          111JA2  dyslexia  female         enabled  \n",
       "3          111JA2  dyslexia  female         enabled  \n",
       "4          111JA2  dyslexia  female         enabled  \n",
       "...           ...       ...     ...             ...  \n",
       "325059     831PA3   control    male        disabled  \n",
       "325060     831PA3   control    male        disabled  \n",
       "325061     831PA3   control    male        disabled  \n",
       "325062     831PA3   control    male        disabled  \n",
       "325063     831PA3   control    male        disabled  \n",
       "\n",
       "[325064 rows x 10 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of fraudulent dyslexia samples: 194902\n"
     ]
    }
   ],
   "source": [
    "# We need to make sure that the samples we extracted have some rows where fraud is True\n",
    "patient_label_map = dict(df[['patient_id', 'label']].values)\n",
    "\n",
    "# Filter the DataFrame for fraudulent samples based on patient label\n",
    "fraudulent_samples = df[df['patient_id'].apply(lambda x: patient_label_map[x] == 'dyslexia')]\n",
    "\n",
    "# Display the shape of the filtered DataFrame\n",
    "print(\"Number of fraudulent dyslexia samples:\", fraudulent_samples.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-16T21:04:23.797075Z",
     "iopub.status.busy": "2023-01-16T21:04:23.796135Z",
     "iopub.status.idle": "2023-01-16T21:04:24.225588Z",
     "shell.execute_reply": "2023-01-16T21:04:24.223789Z",
     "shell.execute_reply.started": "2023-01-16T21:04:23.797018Z"
    }
   },
   "outputs": [],
   "source": [
    "percent_missing=(df.isnull().sum()*100/df.shape[0]).sort_values(ascending=True)\n",
    "plt.title(\"Missing Value Analysis\")\n",
    "plt.xlabel(\"Features\")\n",
    "plt.ylabel(\"% of missing values\")\n",
    "plt.bar(percent_missing.sort_values(ascending=False).index,percent_missing.sort_values(ascending=False),color=(0.1, 0.1, 0.1, 0.1),edgecolor='blue')\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The card_id is defined as one card by one user. A specific user can have multiple cards, which would correspond to multiple different card_ids for this graph. \n",
    "For this reason we will create a new column which is the concatenation of the column User and the Column Card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-16T21:04:24.227819Z",
     "iopub.status.busy": "2023-01-16T21:04:24.227364Z",
     "iopub.status.idle": "2023-01-16T21:04:24.381702Z",
     "shell.execute_reply": "2023-01-16T21:04:24.380181Z",
     "shell.execute_reply.started": "2023-01-16T21:04:24.227781Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"card_id\"] = df[\"User\"].astype(str) + \"_\" + df[\"Card\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-16T21:04:24.384304Z",
     "iopub.status.busy": "2023-01-16T21:04:24.383425Z",
     "iopub.status.idle": "2023-01-16T21:04:24.393573Z",
     "shell.execute_reply": "2023-01-16T21:04:24.391625Z",
     "shell.execute_reply.started": "2023-01-16T21:04:24.384265Z"
    }
   },
   "outputs": [],
   "source": [
    "df.Amount.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-16T21:04:24.396354Z",
     "iopub.status.busy": "2023-01-16T21:04:24.395249Z",
     "iopub.status.idle": "2023-01-16T21:04:24.574714Z",
     "shell.execute_reply": "2023-01-16T21:04:24.573724Z",
     "shell.execute_reply.started": "2023-01-16T21:04:24.396307Z"
    }
   },
   "outputs": [],
   "source": [
    "# We need to strip the ‘$’ from the Amount to cast as a float\n",
    "df[\"Amount\"]=df[\"Amount\"].str.replace(\"$\",\"\").astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-16T21:04:24.577077Z",
     "iopub.status.busy": "2023-01-16T21:04:24.57579Z",
     "iopub.status.idle": "2023-01-16T21:04:24.745287Z",
     "shell.execute_reply": "2023-01-16T21:04:24.743972Z",
     "shell.execute_reply.started": "2023-01-16T21:04:24.5769Z"
    }
   },
   "outputs": [],
   "source": [
    "# time can't be casted to int so so opted to extract the hour and minute\n",
    "df[\"Hour\"] = df[\"Time\"].str [0:2]\n",
    "df[\"Minute\"] = df[\"Time\"].str [3:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-16T21:04:24.747613Z",
     "iopub.status.busy": "2023-01-16T21:04:24.747153Z",
     "iopub.status.idle": "2023-01-16T21:04:24.758257Z",
     "shell.execute_reply": "2023-01-16T21:04:24.756259Z",
     "shell.execute_reply.started": "2023-01-16T21:04:24.747539Z"
    }
   },
   "outputs": [],
   "source": [
    "df.Hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-16T21:04:24.765446Z",
     "iopub.status.busy": "2023-01-16T21:04:24.764947Z",
     "iopub.status.idle": "2023-01-16T21:04:24.921271Z",
     "shell.execute_reply": "2023-01-16T21:04:24.919646Z",
     "shell.execute_reply.started": "2023-01-16T21:04:24.765408Z"
    }
   },
   "outputs": [],
   "source": [
    "df.Minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-16T21:04:24.923964Z",
     "iopub.status.busy": "2023-01-16T21:04:24.923441Z",
     "iopub.status.idle": "2023-01-16T21:04:25.062506Z",
     "shell.execute_reply": "2023-01-16T21:04:25.060936Z",
     "shell.execute_reply.started": "2023-01-16T21:04:24.923909Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.drop([\"Time\",\"User\",\"Card\"],axis=1)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-16T21:04:25.064933Z",
     "iopub.status.busy": "2023-01-16T21:04:25.064389Z",
     "iopub.status.idle": "2023-01-16T21:04:25.079731Z",
     "shell.execute_reply": "2023-01-16T21:04:25.07796Z",
     "shell.execute_reply.started": "2023-01-16T21:04:25.064892Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"Errors?\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-16T21:04:25.081579Z",
     "iopub.status.busy": "2023-01-16T21:04:25.081141Z",
     "iopub.status.idle": "2023-01-16T21:04:25.098267Z",
     "shell.execute_reply": "2023-01-16T21:04:25.096603Z",
     "shell.execute_reply.started": "2023-01-16T21:04:25.081535Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"Errors?\"]= df[\"Errors?\"].fillna(\"No error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two columns Zip and Merchant state contains missing values which can affect our graph. Moreover these information can be extracted from the column Merchant City so we will drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-16T21:04:25.1006Z",
     "iopub.status.busy": "2023-01-16T21:04:25.100132Z",
     "iopub.status.idle": "2023-01-16T21:04:25.129311Z",
     "shell.execute_reply": "2023-01-16T21:04:25.12808Z",
     "shell.execute_reply.started": "2023-01-16T21:04:25.100563Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"Merchant State\",\"Zip\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-16T21:04:25.131409Z",
     "iopub.status.busy": "2023-01-16T21:04:25.131026Z",
     "iopub.status.idle": "2023-01-16T21:04:25.193513Z",
     "shell.execute_reply": "2023-01-16T21:04:25.19207Z",
     "shell.execute_reply.started": "2023-01-16T21:04:25.131375Z"
    }
   },
   "outputs": [],
   "source": [
    "# change the is fraud column to binary \n",
    "df[\"Is Fraud?\"] = df[\"Is Fraud?\"].apply(lambda x: 1 if x == 'Yes' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-16T21:04:25.195994Z",
     "iopub.status.busy": "2023-01-16T21:04:25.195485Z",
     "iopub.status.idle": "2023-01-16T21:04:25.339333Z",
     "shell.execute_reply": "2023-01-16T21:04:25.338041Z",
     "shell.execute_reply.started": "2023-01-16T21:04:25.195927Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"Merchant City\"]=LabelEncoder().fit_transform(df[\"Merchant City\"])\n",
    "df[\"Use Chip\"]=LabelEncoder().fit_transform(df[\"Use Chip\"])\n",
    "df[\"Errors?\"]=LabelEncoder().fit_transform(df[\"Errors?\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-16T21:04:25.341534Z",
     "iopub.status.busy": "2023-01-16T21:04:25.341182Z",
     "iopub.status.idle": "2023-01-16T21:04:25.35339Z",
     "shell.execute_reply": "2023-01-16T21:04:25.35193Z",
     "shell.execute_reply.started": "2023-01-16T21:04:25.341502Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"Errors?\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-16T21:04:25.355589Z",
     "iopub.status.busy": "2023-01-16T21:04:25.355142Z",
     "iopub.status.idle": "2023-01-16T21:04:25.391559Z",
     "shell.execute_reply": "2023-01-16T21:04:25.38995Z",
     "shell.execute_reply.started": "2023-01-16T21:04:25.355554Z"
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GNN for fraud detection:\n",
    "Creating a multigraph for fraud detection using transaction data and applying a Graph Neural Network (GNN) on the edge list can be done in the following steps:\n",
    "\n",
    "1. Prepare the transaction data: Collect and organize the transaction data into a format that can be used to create the edges of the multigraph. For example, each transaction could be represented as a tuple (node1, node2, attributes), where node1 and node2 represent the sender and receiver of the transaction, and attributes is a dictionary containing properties such as the amount, timestamp, and transaction type.\n",
    "\n",
    "2. Create the multigraph: Use the transaction data to create a multigraph using the NetworkX library. The add_edge() method can be used to add edges to the multigraph, where each edge represents a transaction.\n",
    "\n",
    "3. Extract the edges list and their features: Use the edges() method of the multigraph to extract the edges list and their features, which will be used as input to the GNN.\n",
    "\n",
    "4. Apply a GNN on the edge list: Use a GNN library such as PyTorch Geometric, Deep Graph Library (DGL) or Spektral to apply a GNN on the edge list. The GNN will learn representations of the edges in the multigraph and use them to classify the edges as fraudulent or non-fraudulent.\n",
    "\n",
    "5. Evaluation: To evaluate the performance of the GNN, you can split the data into train and test sets, and use the test set to evaluate the accuracy, precision, recall, and F1-score of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph construction \n",
    "\n",
    "When constructing a graph with transaction edges between card_id and merchant_name, the first step is to identify the nodes in the graph. In this case, the card_id and merchant_name represent the nodes in the graph. Each card_id represents a unique credit card and each merchant_name represents a unique merchant. These nodes can be created by extracting the card_id and merchant_name information from the tabular data and storing them in separate lists.\n",
    "\n",
    "Once the nodes have been identified, the next step is to create edges between them. These edges represent the transactions that have taken place between a card_id and a merchant_name. To create the edges, a list of transactions is created and for each transaction, an edge is created between the card_id and merchant_name.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1"
   ]
  },
  {
   "attachments": {
    "7787e1f7-3e13-44c0-9ddb-2e4d67d20c13.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are creating an empty multigraph object called G using the nx.MultiGraph() function from the NetworkX library. Then we add nodes to the graph for each unique card_id and merchant_name from the dataframe df.\n",
    "\n",
    "The add_nodes_from method is used to add nodes to the graph, it takes an iterable as input and creates a node for each element in the iterable. The df[\"card_id\"].unique() will return a list of unique card_ids in the dataframe, and the df[\"Merchant Name\"].unique will return a list of all the merchant names in the dataframe.\n",
    "\n",
    "The type attribute is added to each node, it is used to differentiate between card_id and merchant_name nodes. This will help later on when we want to analyze the graph.\n",
    "\n",
    "**Why did we use a multigraph and not graph?**\n",
    "\n",
    "The same user (card_id) can buy from the same merchant (Merchant Name) multiple times, so we can have multiple edges between the user and the merchant and for this reason we used multigraph instead of graph \n",
    "\n",
    "  ![image.png](attachment:7787e1f7-3e13-44c0-9ddb-2e4d67d20c13.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-16T21:04:59.101133Z",
     "iopub.status.busy": "2023-01-16T21:04:59.09978Z",
     "iopub.status.idle": "2023-01-16T21:04:59.147377Z",
     "shell.execute_reply": "2023-01-16T21:04:59.146367Z",
     "shell.execute_reply.started": "2023-01-16T21:04:59.101074Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create an empty graph\n",
    "G = nx.MultiGraph()\n",
    "\n",
    "# Add nodes to the graph for each unique card_id, merchant_name\n",
    "G.add_nodes_from(df[\"card_id\"].unique(), type='card_id')\n",
    "G.add_nodes_from(df[\"Merchant Name\"].unique(), type='merchant_name')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below adding edges and properties to the edges of a graph. The code iterates through each row of the dataframe, df, and creates a variable for each property then assign it to the edge between the card_id and merchant_name of that row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-16T21:04:59.150566Z",
     "iopub.status.busy": "2023-01-16T21:04:59.149502Z",
     "iopub.status.idle": "2023-01-16T21:05:11.197027Z",
     "shell.execute_reply": "2023-01-16T21:05:11.195877Z",
     "shell.execute_reply.started": "2023-01-16T21:04:59.150526Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add edges and properties to the edges \n",
    "for _, row in df.iterrows():\n",
    "    # Create a variable for each properties for each edge\n",
    "    \n",
    "        year = row[\"Year\"],\n",
    "        month = row[\"Month\"],\n",
    "        day = row[\"Day\"],\n",
    "        hour = row[\"Hour\"],\n",
    "        minute =row[\"Minute\"],\n",
    "        amount = row[\"Amount\"],\n",
    "        use_chip =  row[\"Use Chip\"],\n",
    "        merchant_city = row[\"Merchant City\"],\n",
    "        errors =  row[\"Errors?\"],\n",
    "        mcc = row['MCC']\n",
    "    \n",
    " \n",
    "        G.add_edge(row['card_id'], row['Merchant Name'], year = year , month = month , day = day ,\n",
    "              hour = hour , minute = minute , amount = amount , use_chip = use_chip ,\n",
    "              merchant_city = merchant_city , errors = errors , mcc = mcc)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-16T21:05:11.200279Z",
     "iopub.status.busy": "2023-01-16T21:05:11.198964Z",
     "iopub.status.idle": "2023-01-16T21:05:11.260184Z",
     "shell.execute_reply": "2023-01-16T21:05:11.259136Z",
     "shell.execute_reply.started": "2023-01-16T21:05:11.200228Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get the number of nodes and edges in the graph\n",
    "num_nodes = G.number_of_nodes()\n",
    "num_edges = G.number_of_edges()\n",
    "\n",
    "# Print the number of nodes and edges\n",
    "print(\"Number of nodes:\", num_nodes)\n",
    "print(\"Number of edges:\", num_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-16T21:05:56.996797Z",
     "iopub.status.busy": "2023-01-16T21:05:56.99637Z",
     "iopub.status.idle": "2023-01-16T21:05:57.823056Z",
     "shell.execute_reply": "2023-01-16T21:05:57.821824Z",
     "shell.execute_reply.started": "2023-01-16T21:05:56.996759Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert the graph to an adjacency matrix\n",
    "adj_matrix = nx.adjacency_matrix(G).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-16T21:05:57.825732Z",
     "iopub.status.busy": "2023-01-16T21:05:57.825182Z",
     "iopub.status.idle": "2023-01-16T21:05:57.833229Z",
     "shell.execute_reply": "2023-01-16T21:05:57.83179Z",
     "shell.execute_reply.started": "2023-01-16T21:05:57.825696Z"
    }
   },
   "outputs": [],
   "source": [
    "adj_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will retrieve the properties of a small sample of **nodes** in our graph (G) and print their properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-16T21:05:57.836497Z",
     "iopub.status.busy": "2023-01-16T21:05:57.835126Z",
     "iopub.status.idle": "2023-01-16T21:05:57.860033Z",
     "shell.execute_reply": "2023-01-16T21:05:57.858785Z",
     "shell.execute_reply.started": "2023-01-16T21:05:57.836446Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get a small sample of the nodes in the graph\n",
    "sample_nodes = list(G.nodes())[:10]\n",
    "\n",
    "# Retrieve the properties of the sample nodes\n",
    "node_properties = nx.get_node_attributes(G, 'type')\n",
    "\n",
    "# Print the properties of the sample nodes\n",
    "for node in sample_nodes:\n",
    "    print(f\"Node: {node}, Properties: {node_properties[node]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-16T21:05:57.862762Z",
     "iopub.status.busy": "2023-01-16T21:05:57.862402Z",
     "iopub.status.idle": "2023-01-16T21:05:57.870056Z",
     "shell.execute_reply": "2023-01-16T21:05:57.868163Z",
     "shell.execute_reply.started": "2023-01-16T21:05:57.86273Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_size = 5\n",
    "for i, edge in enumerate(G.edges()):\n",
    "    print(G.get_edge_data(*edge))\n",
    "    if i >= sample_size - 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will retrieve the properties of a small sample of **edges** in our graph (G) and print their properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-16T21:05:57.872391Z",
     "iopub.status.busy": "2023-01-16T21:05:57.871964Z",
     "iopub.status.idle": "2023-01-16T21:05:58.134277Z",
     "shell.execute_reply": "2023-01-16T21:05:58.133092Z",
     "shell.execute_reply.started": "2023-01-16T21:05:57.872358Z"
    }
   },
   "outputs": [],
   "source": [
    "# Retrieve the properties errors of all the edges\n",
    "edge_properties = nx.get_edge_attributes(G, 'errors')\n",
    "\n",
    "# Count the number of edges by property value\n",
    "edge_count_by_property = Counter(edge_properties.values())\n",
    "\n",
    "# Print the count of edges by property value\n",
    "for property_value, count in edge_count_by_property.items():\n",
    "    print(f\"Property value: {property_value}, Count: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-16T21:05:58.136545Z",
     "iopub.status.busy": "2023-01-16T21:05:58.136192Z",
     "iopub.status.idle": "2023-01-16T21:05:58.387685Z",
     "shell.execute_reply": "2023-01-16T21:05:58.386486Z",
     "shell.execute_reply.started": "2023-01-16T21:05:58.136505Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare the data for input into the model\n",
    "edge_list = list(G.edges(data=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-16T21:05:58.390302Z",
     "iopub.status.busy": "2023-01-16T21:05:58.389431Z",
     "iopub.status.idle": "2023-01-16T21:05:58.398607Z",
     "shell.execute_reply": "2023-01-16T21:05:58.397775Z",
     "shell.execute_reply.started": "2023-01-16T21:05:58.390255Z"
    }
   },
   "outputs": [],
   "source": [
    "list(edge_list[i][2].values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a PyTorch neural network model called \"FraudGNN\" which is a type of Graph Neural Network. The model is a simple feedforward neural network with two fully connected (Linear) layers. The first layer has input_dim number of input units and hidden_dim number of output units, while the second layer has hidden_dim number of input units and 1 output unit.\n",
    "The forward function of the model applies the linear layers to the input tensor \"x\" and applies a ReLU activation function to the output of the first linear layer.\n",
    "\n",
    "We also prepare data for input into the model. We define the variable \"edge_list\" which is a list of edges and their associated data in a graph G. Then we create an empty list called \"x\" and iterates over each edge in the edge_list. For each edge, it extracts the values of the edge data, converts them to floats if needed, and append them to the list \"x\". Finally, we convert the list \"x\" to a PyTorch tensor with float datatype, which is ready to be input into the FraudGNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-16T21:22:49.199526Z",
     "iopub.status.busy": "2023-01-16T21:22:49.199098Z",
     "iopub.status.idle": "2023-01-16T21:22:50.703386Z",
     "shell.execute_reply": "2023-01-16T21:22:50.70221Z",
     "shell.execute_reply.started": "2023-01-16T21:22:49.199494Z"
    }
   },
   "outputs": [],
   "source": [
    "class FraudGNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(FraudGNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x.squeeze(-1)\n",
    "\n",
    "# Prepare the data for input into the model\n",
    "edge_list = list(G.edges(data=True))\n",
    "x = []\n",
    "for edge in edge_list:\n",
    "    edge_values = list(edge[2].values())\n",
    "    edge_values = [float(i[0]) if type(i) == tuple and type(i[0]) == str else i[0] if type(i) == tuple else i for i in edge_values]\n",
    "    x.append(edge_values)\n",
    "x = torch.tensor(x, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-16T21:22:52.214265Z",
     "iopub.status.busy": "2023-01-16T21:22:52.213847Z",
     "iopub.status.idle": "2023-01-16T21:22:52.220759Z",
     "shell.execute_reply": "2023-01-16T21:22:52.219048Z",
     "shell.execute_reply.started": "2023-01-16T21:22:52.214232Z"
    }
   },
   "outputs": [],
   "source": [
    "target = torch.tensor(df['Is Fraud?'].values, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-16T21:22:55.479953Z",
     "iopub.status.busy": "2023-01-16T21:22:55.479572Z",
     "iopub.status.idle": "2023-01-16T21:22:55.486403Z",
     "shell.execute_reply": "2023-01-16T21:22:55.485519Z",
     "shell.execute_reply.started": "2023-01-16T21:22:55.479922Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the model\n",
    "input_dim = len(x[0])\n",
    "hidden_dim = 16\n",
    "model = FraudGNN(input_dim, hidden_dim)\n",
    "num_epochs=201\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-16T21:22:58.153084Z",
     "iopub.status.busy": "2023-01-16T21:22:58.151218Z",
     "iopub.status.idle": "2023-01-16T21:23:02.723745Z",
     "shell.execute_reply": "2023-01-16T21:23:02.722551Z",
     "shell.execute_reply.started": "2023-01-16T21:22:58.153021Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "for i in range(num_epochs):\n",
    "    # Forward pass\n",
    "    output = model(x)\n",
    "    # Compute the loss\n",
    "    loss = criterion(output, target)\n",
    "    if i % 20 == 0:\n",
    "        print(f'Epoch: {i}, Loss: {loss.item()}')\n",
    "    # Zero the gradients\n",
    "    optimizer.zero_grad()\n",
    "    # Perform backpropagation\n",
    "    loss.backward()\n",
    "    # Update the parameters\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part we will base our work on the [paper](https://www.sciencedirect.com/science/article/abs/pii/S0957417421017449) **Inductive Graph Representation Learning for fraud detection** written by RafaëlVan Belle, Charles Van Damme, Hendrik Tytgat and JochenDe Weerdt. \n",
    "\n",
    "Charles has created a python library with the name of inductiveGRL for the experimental setup of their paper. \n",
    "\n",
    "Library overview :\n",
    "\n",
    "1. Transaction Data\n",
    "Any dataset that can be transformed into a graph can be used in our experimental setup. For our research, we used a real-life dataset to construct credit card transaction networks containing millions of transactions. This dataset includes information on the following features: anonymized identification of clients and merchants, merchant category code, country, monetary amount, time, acceptance, and fraud label. This real-life dataset is highly imbalanced and contains only 0.65% fraudulent transactions. Note that the demo data in this repository is artificaly generated for demonstration purposes. The Timeframes component derives the different timeframes for a rolling window setup given a step and window size.\n",
    "\n",
    "2. Graph Construction\n",
    "The GraphConstruction component constructs the graphs that will be used by graph representation learners (e.g. FI-GRL and GraphSAGE) to learn node embeddings. We designed the credit card transaction networks as heterogeneous tripartite graphs containing client, merchant and transaction nodes. Because of this tripartite setup, representations can be learned for the transaction nodes. Only the transaction nodes are configured with node features.\n",
    "\n",
    "3. GraphSAGE\n",
    "The HinSAGE code deploys a supervised, heterogeneous implementation of the GraphSAGE framework called HinSAGE, to learn embeddings of the transaction nodes in the aforementioned graphs.\n",
    "\n",
    "4. FI-GRL\n",
    "The FIGRL code learns embeddings of the transaction nodes in the aforementioned graphs using the Fast Inductive Graph Representation Learning Framework. We call the Matlab implementation of FI-GRL from our Jupyter notebooks, which requires an appropriate installation of matlab.engine in the same folder as the notebooks. If you wish to run FI-GRL from Python, please run the following command in Matlab:\n",
    "\n",
    "cd (fullfile(matlabroot,'extern','engines','python'))\n",
    "system('python setup.py install')\n",
    "\n",
    "This will generate a folder in matlabroot\\extern\\engines\\python\\build\\lib called 'matlab' please copy this folder and place it on the same location as the notebook from which you want to call matlab.engine. If you don't know your matlab root, running 'matlabroot' in Matlab will return the appropriate path.\n",
    "\n",
    "5. Classifier\n",
    "The penultimate component in our pipeline uses the transaction node embeddings to classify the transaction nodes as fraudulent or legitimate. We chose to rely on XGBoost as a classification model, but other classifiers can easily be implemented.\n",
    "\n",
    "6. Evaluation\n",
    "The Evaluation component contains functions for the Lift score, Lift curve and precision-recall curve. We focused on these evaluation metrics given the highly imbalanced nature of our dataset. However, this code can easily be extended to contain other evaluation metrics such as ROC plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-16T21:08:59.216406Z",
     "iopub.status.busy": "2023-01-16T21:08:59.215951Z",
     "iopub.status.idle": "2023-01-16T21:09:41.666384Z",
     "shell.execute_reply": "2023-01-16T21:09:41.664133Z",
     "shell.execute_reply.started": "2023-01-16T21:08:59.216369Z"
    }
   },
   "outputs": [],
   "source": [
    "#library installation\n",
    "!pip install inductiveGRL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-16T21:09:41.672131Z",
     "iopub.status.busy": "2023-01-16T21:09:41.671665Z",
     "iopub.status.idle": "2023-01-16T21:09:47.765858Z",
     "shell.execute_reply": "2023-01-16T21:09:47.764945Z",
     "shell.execute_reply.started": "2023-01-16T21:09:41.672086Z"
    }
   },
   "outputs": [],
   "source": [
    "# necessary imports of this part\n",
    "from inductiveGRL.graphconstruction import GraphConstruction\n",
    "from inductiveGRL.hinsage import HinSAGE_Representation_Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-16T21:09:47.771863Z",
     "iopub.status.busy": "2023-01-16T21:09:47.76982Z",
     "iopub.status.idle": "2023-01-16T21:09:47.780728Z",
     "shell.execute_reply": "2023-01-16T21:09:47.778742Z",
     "shell.execute_reply.started": "2023-01-16T21:09:47.771823Z"
    }
   },
   "outputs": [],
   "source": [
    "# Global parameters:\n",
    "embedding_size = 64\n",
    "add_additional_data = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will split our data 70% to train_data and 30% for inductive data that will be used to test the model's ability to generalize to new, unseen data.\n",
    "\n",
    "First we calculate the cutoff point for the split using the formula \"cutoff = round(0.7*len(df))\" where 0.7 represents 70% of the data, and len(df) is the total number of rows in the dataframe. The round function is used to round the cutoff point to the nearest whole number.\n",
    "\n",
    "Second we assign the first \"cutoff\" rows of the dataframe to the variable \"train_data\" by calling the head() function on the dataframe and passing the cutoff point as an argument. These rows will be used as the training data.\n",
    "\n",
    "Last we assign the remaining rows of the dataframe (the rows after the cutoff point) to the variable \"inductive_data\" by calling the tail() function on the dataframe and passing the number of remaining rows (len(df) - cutoff) as an argument. These rows will be used as the inductive data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-16T21:09:47.784848Z",
     "iopub.status.busy": "2023-01-16T21:09:47.784038Z",
     "iopub.status.idle": "2023-01-16T21:09:47.801896Z",
     "shell.execute_reply": "2023-01-16T21:09:47.800276Z",
     "shell.execute_reply.started": "2023-01-16T21:09:47.78479Z"
    }
   },
   "outputs": [],
   "source": [
    "# we will take 70% of our dataset as traindata\n",
    "cutoff = round(0.7*len(df)) \n",
    "train_data = df.head(cutoff)\n",
    "inductive_data = df.tail(len(df)-cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-16T21:09:47.804188Z",
     "iopub.status.busy": "2023-01-16T21:09:47.803762Z",
     "iopub.status.idle": "2023-01-16T21:09:47.818779Z",
     "shell.execute_reply": "2023-01-16T21:09:47.817788Z",
     "shell.execute_reply.started": "2023-01-16T21:09:47.804148Z"
    }
   },
   "outputs": [],
   "source": [
    "print('The distribution of fraud for the train data is:\\n', train_data['Is Fraud?'].value_counts())\n",
    "print('The distribution of fraud for the inductive data is:\\n', inductive_data['Is Fraud?'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graphe construction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a graph from a train_data using the GraphConstruction class. First we create the dataframes for the node data, second we define the nodes and edges, third  we create a dictionary of features, and finally we create a graph object, and calls the get_stellargraph() method to get the StellarGraph object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-16T21:09:47.820745Z",
     "iopub.status.busy": "2023-01-16T21:09:47.819916Z",
     "iopub.status.idle": "2023-01-16T21:09:49.98663Z",
     "shell.execute_reply": "2023-01-16T21:09:49.985174Z",
     "shell.execute_reply.started": "2023-01-16T21:09:47.820707Z"
    }
   },
   "outputs": [],
   "source": [
    "transaction_node_data = train_data.drop(\"card_id\", axis=1).drop(\"Merchant Name\", axis=1).drop('Is Fraud?', axis=1)\n",
    "client_node_data = pd.DataFrame([1]*len(train_data[\"card_id\"].unique())).set_index(train_data[\"card_id\"].unique())\n",
    "merchant_node_data = pd.DataFrame([1]*len(train_data[\"Merchant Name\"].unique())).set_index(train_data[\"Merchant Name\"].unique())\n",
    "\n",
    "nodes = {\"client\":train_data.card_id, \"merchant\":train_data[\"Merchant Name\"], \"transaction\":train_data.index}\n",
    "edges = [zip(train_data.card_id, train_data.index),zip(train_data[\"Merchant Name\"], train_data.index)]\n",
    "features = {\"transaction\": transaction_node_data, 'client': client_node_data, 'merchant': merchant_node_data}\n",
    "\n",
    "graph = GraphConstruction(nodes, edges, features)\n",
    "S = graph.get_stellargraph()\n",
    "print(S.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-16T21:09:49.989169Z",
     "iopub.status.busy": "2023-01-16T21:09:49.988488Z",
     "iopub.status.idle": "2023-01-16T21:22:25.952671Z",
     "shell.execute_reply": "2023-01-16T21:22:25.951482Z",
     "shell.execute_reply.started": "2023-01-16T21:09:49.98913Z"
    }
   },
   "outputs": [],
   "source": [
    "#GraphSAGE parameters\n",
    "num_samples = [2,32]\n",
    "embedding_node_type = \"transaction\"\n",
    "\n",
    "hinsage = HinSAGE_Representation_Learner(embedding_size, num_samples, embedding_node_type)\n",
    "trained_hinsage_model, train_emb = hinsage.train_hinsage(S, list(train_data.index), train_data['Is Fraud?'], batch_size=5, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliogtaphy : \n",
    "\n",
    "**Papers** \n",
    "\n",
    "Inductive Graph Representation Learning for fraud detection (paper)  : [Link](https://www.sciencedirect.com/science/article/abs/pii/S0957417421017449)\n",
    "\n",
    "Intelligent Financial Fraud Detection Practices: An\n",
    "Investigation : [Link](https://arxiv.org/ftp/arxiv/papers/1510/1510.07165.pdf)\n",
    "\n",
    "Modeling Relational Data with Graph Convolutional Networks : [Link](https://arxiv.org/pdf/1703.06103.pdf) \n",
    "\n",
    "For more papers check this github [link](https://github.com/benedekrozemberczki/awesome-fraud-detection-papers)\n",
    "\n",
    "**Library** \n",
    "\n",
    "Inductive-Graph-Representation-Learning-for-Fraud-Detection (library) : [Link](https://github.com/Charlesvandamme/Inductive-Graph-Representation-Learning-for-Fraud-Detection)\n",
    "\n",
    "**Dataset** \n",
    "\n",
    "IBM dataset : \n",
    "* [Link1](https://github.com/IBM/TabFormer) github\n",
    "* [Link2](https://ibm.ent.box.com/v/tabformer-data) IBM@Box\n",
    "* [Link3](https://www.kaggle.com/datasets/ealtman2019/credit-card-transactions) kaggle\n",
    "\n",
    "**Others** \n",
    "\n",
    "11 Categorical Encoders and Benchmark : [Link](https://www.kaggle.com/code/subinium/11-categorical-encoders-and-benchmark#1.-Label-Encoder-(LE),-Ordinary-Encoder(OE)) \n",
    "\n",
    "StellarGraph : [Link](https://stellargraph.readthedocs.io/en/stable/README.html#example-gcn)\n",
    "\n",
    "NetworkX : [Link](https://networkx.org)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 1478095,
     "sourceId": 2705785,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30357,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
